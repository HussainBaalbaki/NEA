{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZtcwBmVhdKqtwI/L6ETnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HussainBaalbaki/NEA/blob/Master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNvyzJntDRs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import gdown\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import regularizers\n",
        "from IPython import display\n",
        "\n",
        "#  the seed value for  reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = 'drive/My Drive/data'\n",
        "\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "\n",
        "commands = ['WakeWord', 'environmentnoise']\n",
        "print('Commands:', commands)\n",
        "\n",
        "def load_audio_file(file_path):\n",
        "    audio_binary = tf.io.read_file(file_path)\n",
        "\n",
        "\n",
        "    if file_path.endswith('.wav'):\n",
        "        audio, sample_rate = tf.audio.decode_wav(audio_binary)\n",
        "    elif file_path.endswith('.mp3'):\n",
        "        raise NotImplementedError(\"ERROR 1-CHECK files type\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "    return audio, sample_rate\n",
        "\n",
        "def preprocess(file_path):\n",
        "    audio, sample_rate = load_audio_file(file_path)\n",
        "    return audio\n",
        "\n",
        "commands = ['WakeWord', 'environmentnoise']\n",
        "print('Commands:', commands)\n",
        "\n",
        "Batch_size=1200\n",
        "Validation_split=0.4\n",
        "Output_sequence_length=16000\n",
        "\n",
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=data_dir,\n",
        "    batch_size=Batch_size,\n",
        "    validation_split=Validation_split,\n",
        "    seed=0,\n",
        "    output_sequence_length=Output_sequence_length,\n",
        "    subset='both',\n",
        "    labels='inferred',\n",
        "    class_names=commands\n",
        ")\n",
        "label_names = np.array(train_ds.class_names)\n",
        "print()\n",
        "print(\"Label names:\", label_names)\n",
        "\n",
        "def squeeze(audio, labels):\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  return audio, labels\n",
        "\n",
        "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = val_ds.shard(num_shards=2, index=0)\n",
        "val_ds = val_ds.shard(num_shards=2, index=1)\n",
        "\n",
        "def get_spectrogram(waveform, frame_length=255, frame_step=128, desired_shape=(125, 125)):\n",
        "  spectrogram = tf.signal.stft(\n",
        "      waveform, frame_length=frame_length, frame_step=frame_step)\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = spectrogram[..., tf.newaxis]\n",
        "\n",
        "  spectrogram = tf.image.resize(spectrogram, desired_shape)\n",
        "  return spectrogram\n",
        "\n",
        "for example_audio, example_labels in train_ds.take(1):\n",
        "  print(example_audio.shape)\n",
        "  print(example_labels.shape)\n",
        "\n",
        "\n",
        "def plot_spectrogram(spectrogram, ax):\n",
        "  if len(spectrogram.shape) > 2:\n",
        "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
        "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
        "  height = log_spec.shape[0]\n",
        "  width = log_spec.shape[1]\n",
        "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "  Y = range(height)\n",
        "  ax.pcolormesh(X, Y, log_spec)\n",
        "\n",
        "def make_spec_ds(ds):\n",
        "  return ds.map(\n",
        "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
        "      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_spectrogram_ds = make_spec_ds(train_ds)\n",
        "val_spectrogram_ds = make_spec_ds(val_ds)\n",
        "test_spectrogram_ds = make_spec_ds(test_ds)\n",
        "\n",
        "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
        "    break\n",
        "\n",
        "input_shape = example_spectrograms.shape[1:]\n",
        "print('Input shape:', input_shape)\n",
        "num_labels = 1\n",
        "\n",
        "\n",
        "norm_layer = layers.Normalization()\n",
        "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # Resize the input images to 32x32 pixels\n",
        "    layers.Resizing(32, 32),\n",
        "\n",
        "    # Normalization layer to scale input data\n",
        "    norm_layer,\n",
        "\n",
        "    # Convolutional Block 1 with L2 regularization and Dropout\n",
        "    layers.Conv2D(32, 3, activation='relu', kernel_regularizer=regularizers.l2(0.007)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),  # Increased dropout rate to 0.3 (edit12)\n",
        "    norm_layer,\n",
        "\n",
        "    # Flattening the output of the convolutional layers\n",
        "    layers.Flatten(),\n",
        "    # Dense Block with Dropout and L2 regularization\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.007)),\n",
        "    layers.Dropout(0.5),  # Increased dropout rate to 0.5\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    layers.Dense(num_labels, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(                                                                    # Binary loss function difference between the true labels \"WakeWord\", \"enviromentnoise\" and prediction\n",
        "    optimizer=tf.keras.optimizers.Adam(),                                         # sigma function fr add images of the function + explination\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "\n",
        "class_weights = {0: 1.0, 1: 22.0}\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "history = model.fit(\n",
        "    train_spectrogram_ds,\n",
        "    validation_data=val_spectrogram_ds,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weights,\n",
        "    ##callbacks=[early_stopping_callback],\n",
        ")\n",
        "\n",
        "metrics = history.history\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss [BinaryCrossEntropy]')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.ylim([0, 100])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "\n",
        "model.evaluate(test_spectrogram_ds, return_dict=True)\n",
        "y_pred = model.predict(test_spectrogram_ds)\n",
        "y_pred = tf.round(y_pred)\n",
        "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s, lab: lab)), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx,\n",
        "            xticklabels=['Non-Wake Word', 'Wake Word'],\n",
        "            yticklabels=['Non-Wake Word', 'Wake Word'],\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()\n",
        "\n",
        "x = data_dir/'WakeWord/david_20240831_014725_louder - Copy (5) - Copy.wav'\n",
        "x = tf.io.read_file(str(x))\n",
        "x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
        "x = tf.squeeze(x, axis=-1)\n",
        "waveform = x\n",
        "x = get_spectrogram(x)\n",
        "x = x[tf.newaxis,...]\n",
        "\n",
        "prediction = model(x)\n",
        "print(f'Prediction: {tf.round(prediction).numpy()} (0=Non-Wake Word, 1=Wake Word)')\n",
        "\n",
        "display.display(display.Audio(waveform, rate=16000))\n",
        "\n",
        "class ExportModel(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.__call__.get_concrete_function(x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
        "    self.__call__.get_concrete_function(x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    if x.dtype == tf.string:\n",
        "      x = tf.io.read_file(x)\n",
        "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
        "      x = tf.squeeze(x, axis=-1)\n",
        "      x = x[tf.newaxis, :]\n",
        "\n",
        "    x = get_spectrogram(x)\n",
        "    result = self.model(x, training=False)\n",
        "\n",
        "    class_id = tf.round(result)  # Output 0 or 1\n",
        "    return {'predictions': result, 'class_id': class_id}\n",
        "\n",
        "\n",
        "export = ExportModel(model)\n",
        "tf.saved_model.save(export, \"saved_model\")\n",
        "\n",
        "imported = tf.saved_model.load(\"saved_model\")\n",
        "imported(waveform[tf.newaxis, :])\n",
        "\n",
        "\n",
        "model.save('my_model.h5')\n",
        "\n",
        "\n",
        "\n",
        "!zip -r ./my_model.h5.zip ./my_model.h5"
      ]
    }
  ]
}