{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HussainBaalbaki/NEA/blob/Master/V2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CdffZZf1v5qV"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q tensorflow tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT2y1opRwf_H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import gdown\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import regularizers\n",
        "from IPython import display\n",
        "\n",
        "#  the seed value for  reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = 'drive/My Drive/data'\n",
        "\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "\n",
        "commands = ['WakeWord', 'environmentnoise']\n",
        "print('Commands:', commands)\n",
        "\n",
        "def load_audio_file(file_path):\n",
        "    audio_binary = tf.io.read_file(file_path)\n",
        "\n",
        "\n",
        "    if file_path.endswith('.wav'):\n",
        "        audio, sample_rate = tf.audio.decode_wav(audio_binary)\n",
        "    elif file_path.endswith('.mp3'):\n",
        "        raise NotImplementedError(\"ERROR 1-CHECK files type\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "    return audio, sample_rate\n",
        "\n",
        "def preprocess(file_path):\n",
        "    audio, sample_rate = load_audio_file(file_path)\n",
        "    return audio\n",
        "\n",
        "commands = ['WakeWord', 'environmentnoise']\n",
        "print('Commands:', commands)"
      ],
      "metadata": {
        "id": "wVhrUFOwfCEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM1V9fkfxyp4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdzPasLTxGWJ"
      },
      "outputs": [],
      "source": [
        "Batch_size=1200\n",
        "Validation_split=0.4\n",
        "Output_sequence_length=16000\n",
        "\n",
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=data_dir,\n",
        "    batch_size=Batch_size,\n",
        "    validation_split=Validation_split,\n",
        "    seed=0,\n",
        "    output_sequence_length=Output_sequence_length,\n",
        "    subset='both',\n",
        "    labels='inferred',\n",
        "    class_names=commands\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    dataset = tf.keras.utils.audio_dataset_from_directory(\n",
        "        directory=data_dir,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        seed=0,\n",
        "        output_sequence_length=16000,\n",
        "        subset='both',\n",
        "        labels='inferred'\n",
        "    )\n",
        "\n",
        "label_names = np.array(train_ds.class_names)\n",
        "print()\n",
        "print(\"Label names:\", label_names)\n"
      ],
      "metadata": {
        "id": "VWEGJMmbihJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f0c7aa-e69a-4222-b8ad-fcaaf6da87c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label names: ['WakeWord' 'environmentnoise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def squeeze(audio, labels):\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  return audio, labels"
      ],
      "metadata": {
        "id": "Ui9FFGxqpG0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hl1zbH0idKyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = val_ds.shard(num_shards=2, index=0)\n",
        "val_ds = val_ds.shard(num_shards=2, index=1)"
      ],
      "metadata": {
        "id": "TL6ohvDucf_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AzX06-eseJiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spectrogram(waveform, frame_length=255, frame_step=128, desired_shape=(125, 125)):\n",
        "  spectrogram = tf.signal.stft(\n",
        "      waveform, frame_length=frame_length, frame_step=frame_step)\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = spectrogram[..., tf.newaxis]\n",
        "\n",
        "  spectrogram = tf.image.resize(spectrogram, desired_shape)\n",
        "  return spectrogram\n",
        "\n",
        "for example_audio, example_labels in train_ds.take(1):\n",
        "  print(example_audio.shape)\n",
        "  print(example_labels.shape)"
      ],
      "metadata": {
        "id": "5WHX5_PWdNuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spectrogram(spectrogram, ax):\n",
        "  if len(spectrogram.shape) > 2:\n",
        "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
        "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
        "  height = log_spec.shape[0]\n",
        "  width = log_spec.shape[1]\n",
        "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "  Y = range(height)\n",
        "  ax.pcolormesh(X, Y, log_spec)"
      ],
      "metadata": {
        "id": "6fblfCAznACH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "758kCLSRT-F7"
      },
      "outputs": [],
      "source": [
        "def make_spec_ds(ds):\n",
        "  return ds.map(\n",
        "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
        "      num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsaLmM5Mt9T0"
      },
      "outputs": [],
      "source": [
        "train_spectrogram_ds = make_spec_ds(train_ds)\n",
        "val_spectrogram_ds = make_spec_ds(val_ds)\n",
        "test_spectrogram_ds = make_spec_ds(test_ds)\n",
        "\n",
        "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9brxhFndeQjm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB6qE-vpIAre"
      },
      "outputs": [],
      "source": [
        "input_shape = example_spectrograms.shape[1:]\n",
        "print('Input shape:', input_shape)\n",
        "num_labels = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_layer = layers.Normalization()\n",
        "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n"
      ],
      "metadata": {
        "id": "H6sBEhIOneTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzNnu6viuC2w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6QCShG0uABX"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # Resize the input images to 32x32 pixels\n",
        "    layers.Resizing(32, 32),\n",
        "\n",
        "    # Normalization layer to scale input data\n",
        "    norm_layer,\n",
        "\n",
        "    # Convolutional Block 1 with L2 regularization and Dropout\n",
        "    layers.Conv2D(32, 3, activation='relu', kernel_regularizer=regularizers.l2(0.007)),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),  # Increased dropout rate to 0.3 (edit12)\n",
        "    norm_layer,\n",
        "\n",
        "    # Flattening the output of the convolutional layers\n",
        "    layers.Flatten(),\n",
        "    # Dense Block with Dropout and L2 regularization\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.007)),\n",
        "    layers.Dropout(0.5),  # Increased dropout rate to 0.5\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    layers.Dense(num_labels, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "U4krsu_WeawY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JzIq6xYuV0B"
      },
      "outputs": [],
      "source": [
        "model.compile(                                                                    # Binary loss function difference between the true labels \"WakeWord\", \"enviromentnoise\" and prediction\n",
        "    optimizer=tf.keras.optimizers.Adam(),                                         # sigma function fr add images of the function + explination\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsb5EJnsuUQj"
      },
      "outputs": [],
      "source": [
        "class_weights = {0: 1.0, 1: 22.0}\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "history = model.fit(\n",
        "    train_spectrogram_ds,\n",
        "    validation_data=val_spectrogram_ds,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weights,\n",
        "    ##callbacks=[early_stopping_callback],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = history.history\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss [BinaryCrossEntropy]')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.ylim([0, 100])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "\n",
        "model.evaluate(test_spectrogram_ds, return_dict=True)"
      ],
      "metadata": {
        "id": "TG7SizFregNP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lss8vQyaubVh"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_spectrogram_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHBzzrulug-p"
      },
      "outputs": [],
      "source": [
        "y_pred = tf.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jCE9YAnuisR"
      },
      "outputs": [],
      "source": [
        "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s, lab: lab)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j73egnhGukn1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx,\n",
        "            xticklabels=['Non-Wake Word', 'Wake Word'],\n",
        "            yticklabels=['Non-Wake Word', 'Wake Word'],\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL295f6kunhM"
      },
      "outputs": [],
      "source": [
        "x = data_dir/'WakeWord/david_20240831_014725_louder - Copy (5) - Copy.wav'\n",
        "x = tf.io.read_file(str(x))\n",
        "x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
        "x = tf.squeeze(x, axis=-1)\n",
        "waveform = x\n",
        "x = get_spectrogram(x)\n",
        "x = x[tf.newaxis,...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xxafL06upb4"
      },
      "outputs": [],
      "source": [
        "prediction = model(x)\n",
        "print(f'Prediction: {tf.round(prediction).numpy()} (0=Non-Wake Word, 1=Wake Word)')\n",
        "display.display(display.Audio(waveform, rate=16000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIlqUNjvuuls"
      },
      "outputs": [],
      "source": [
        "class ExportModel(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.__call__.get_concrete_function(\n",
        "            x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
        "        self.__call__.get_concrete_function(\n",
        "           x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqDHXymPPnMw"
      },
      "outputs": [],
      "source": [
        "class ExportModel(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.__call__.get_concrete_function(x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
        "    self.__call__.get_concrete_function(x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    if x.dtype == tf.string:\n",
        "      x = tf.io.read_file(x)\n",
        "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
        "      x = tf.squeeze(x, axis=-1)\n",
        "      x = x[tf.newaxis, :]\n",
        "\n",
        "    x = get_spectrogram(x)\n",
        "    result = self.model(x, training=False)\n",
        "\n",
        "    class_id = tf.round(result)  # Output 0 or 1\n",
        "    return {'predictions': result, 'class_id': class_id}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export = ExportModel(model)\n",
        "tf.saved_model.save(export, \"saved_model\")\n",
        "\n",
        "imported = tf.saved_model.load(\"saved_model\")\n",
        "imported(waveform[tf.newaxis, :])\n",
        "\n",
        "\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "id": "2HRhFyHce2JQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru7nDIgbuxV2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyPDQauPI46PNbg2ELkQqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}